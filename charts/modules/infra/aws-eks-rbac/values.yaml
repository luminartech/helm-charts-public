---
## @section Global parameters
## Global parameters
## These variables are accessible to all dependency helm charts.
##

global:
  ## @param global.chartNameOverride Overrides the chart name.
  ##
  chartNameOverride: ""
  ## @param global.releaseNameOverride Overrides the release name.
  ##
  releaseNameOverride: ""
  ## @param global.tags Define common tags for all IAC and app resources generated by this chart.
  ##
  tags: {}
  ## @param global.labels Define common labels for all IAC and app resources generated by this chart.
  ##
  labels: {}
  ## @param global.annotations Define common annotations for all IAC and app resources generated by this chart.
  ##
  annotations: {}
  ## @param global.awsAccountId Default aws account id for crossplane aws provider resources. Quotes are important, value must be a string.
  ##
  awsAccountId: "0123456789"
  ## @param global.awsMgmtAccountId Management AWS account that runs the main mgmt cluster + argocd + crossplane.
  ## Crossplane and argocd IAM roles will be allowed to access this cluster and manage resources in the AWS account.
  ##
  awsMgmtAccountId: "0123456789"
  ## @param global.awsRegion Default aws region for crossplane aws provider resources.
  ##
  awsRegion: "us-east-2"
  ## @param global.providerConfigRef.name Default crossplane provider all resources generated for crossplane.
  ##
  providerConfigRef:
    name: "crossplane-provider-config-aws"
  ## @param global.awsDeletionPolicy Default crossplane deletion policy for all resources deployed by this helm chart..
  ## This can be overriden for each resource in its section
  ##
  awsDeletionPolicy: "Orphan"
  ## @param global.environment Environment name for the eks cluster
  ##
  environment: "dev"
  ## @param global.argocdIAMRole Argo CD IAM role to grant cross account assume role permissions
  ##
  argocdIAMRole: "argo-cd"
  ## @param global.crossplaneNamespace Crossplane namespace for storing the EKS cluster config
  ##
  crossplaneNamespace: "infra-crossplane"
  ## @param global.crossplaneIAMRole Crossplane IAM Role
  ##
  crossplaneIAMRole: "crossplane-provider-aws"
  ## @param global.karpenterNodeRoleName Karpenter IAM Role
  ##
  karpenterNodeRoleName: "infra-aws-eks-karpenter-node"
  ## @param global.teamAdminIAMRole Grant EKS admin permissions to this IAM Role
  ##
  teamAdminIAMRole: "infra-admins"
  ## @param global.additionalAwsAuthMapRoles Extra lines to be added to mapRoles paramenter in aws-auth ConfigMap
  ##
  additionalAwsAuthMapRoles: ""

## @section Dependency: crossplane-aws-iam upstream helm chart parameters
## ref: https://github.com/luminartech/helm-charts-public/blob/main/charts/iac/crossplane-aws-iam/values.yaml
## AWS resources parameters.
## items: Dict of one or more resources of its kind.
## items._: Name of the resource in the kubernetes. "_" generates a default name as releaseName-object name
## ref: https://github.com/luminartech/helm-charts-public/blob/478ec718b93063f1eccfa591189ab0f59bf3fd1e/charts/shared/common-gitops/templates/_names.tpl#L50
##
crossplane-aws-iam:
  ## @skip crossplane-aws-iam.enabled
  enabled: false

  ## @skip crossplane-aws-iam.RolePolicyAttachment
  RolePolicyAttachment:
    items:
      _:
        forProvider:
          policyArnRef:
            name: '{{ include "common-gitops.names.release" . }}'
          roleRef:
            name: '{{ include "common-gitops.names.release" . }}'

  ## @skip crossplane-aws-iam.Policy
  Policy:
    items:
      _:
        forProvider:
          description: "IAM Policy for eks-rbac"
          # TODO: Implement least privileges model
          policy:
            Statement:
              allowEKSAll:
                Effect: Allow
                Action: eks:*
                Resource: '*'

  ## @skip crossplane-aws-iam.Role
  Role:
    items:
      _:
        forProvider:
          assumeRolePolicy:
            Statement:
              allowEC2AssumeRole:
                Effect: Allow
                Principal:
                  Service: ec2.amazonaws.com
                Action: sts:AssumeRole
              allowAssumeRoleWebIdentity:
                Effect: Allow
                Principal:
                  AWS: arn:aws:iam::{{ .Values.global.awsMgmtAccountId }}:role/{{ .Values.global.argocdIAMRole }}
                Action: sts:AssumeRoleWithWebIdentity
              allowSelfAssumeRole:
                Effect: Allow
                Principal:
                  AWS: "*"
                Action: "sts:AssumeRole"
                Condition:
                  ArnLike:
                    "aws:PrincipalArn": "arn:aws:iam::{{ .Values.global.awsMgmtAccountId }}:role/{{ .Values.global.argocdIAMRole }}"

  ## @skip crossplane-aws-iam.OpenIDConnectProvider
  OpenIDConnectProvider:
    items:
      _:
        annotations:
          crossplane.io/external-name: 'arn:aws:iam::{{ .Values.global.awsAccountId }}:oidc-provider/oidc.eks.{{ .Values.global.awsRegion }}.amazonaws.com/id/{{ .Values.global.eksHash }}'
        # Note: We DO NOT want this provider to go away no matter what.
        #       Setting deletionPolicy to Delete will risk all application access to AWS in the cluster
        deletionPolicy: Orphan
        forProvider:
          clientIdList:
            - sts.amazonaws.com
          thumbprintList:
            # This thumbprint is same for all eks clusters
            - "9e99a48a9960b14926bb7f3b02e22da2b0ab7280"
          url: https://oidc.eks.{{ .Values.global.awsRegion }}.amazonaws.com/id/{{ .Values.global.eksHash }}

## @section Dependency: crossplane-kubernetes upstream helm chart parameters
##
crossplane-kubernetes:
  ## @skip crossplane-kubernetes.enabled
  enabled: false
  ## @skip crossplane-kubernetes.ProviderConfig
  ProviderConfig:
    items:
      # Can not move it to crossplane-provider because it depends on particular secret
      _:
        credentials:
          secretRef:
            key: "kubeconfig"
            name: '{{ include "common-gitops.names.release" . }}'
            namespace: '{{ .Values.global.crossplaneNamespace }}'
          source: Secret
  ## @skip crossplane-kubernetes.Object
  Object:
    items:
      aws-auth:
        forProvider:
          manifest:
            apiVersion: v1
            kind: ConfigMap
            metadata:
              labels:
                app.kubernetes.io/name: '{{ include "common-gitops.names.release" . }}'
                app.kubernetes.io/instance: kubernetes
              name: aws-auth
              namespace: kube-system
            data:
              mapAccounts: |
                []
              mapRoles: |
                - rolearn: 'arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ .Values.global.crossplaneIAMRole }}'
                  username: 'arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ .Values.global.crossplaneIAMRole }}'
                  groups:
                    - system:masters
                - groups:
                  - "system:bootstrappers"
                  - "system:nodes"
                  rolearn: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ include "common-gitops.names.release" . }}-node"
                  username: "system:node:{{ "{{" }}EC2PrivateDNSName{{ "}}" }}"
                - groups:
                  - "system:bootstrappers"
                  - "system:nodes"
                  # For windows nodes
                  - "eks:kube-proxy-windows"
                  rolearn: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ .Values.global.karpenterNodeRoleName }}"
                  username: "system:node:{{ "{{" }}EC2PrivateDNSName{{ "}}" }}"
                - groups:
                  - system:masters
                  rolearn: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ include "common-gitops.names.release" . }}"
                  username: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ include "common-gitops.names.release" . }}"
                - groups:
                  - system:masters
                  rolearn: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ .Values.global.teamAdminIAMRole }}"
                  username: "arn:aws:iam::{{ .Values.global.awsAccountId }}:role/{{ .Values.global.teamAdminIAMRole }}"
                {{ .Values.global.additionalAwsAuthMapRoles }}
        providerConfigRef:
          name: '{{ include "common-gitops.names.release" . }}'

      serviceaccount:
        forProvider:
          manifest:
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              labels:
                app.kubernetes.io/name: '{{ include "common-gitops.names.release" . }}'
                app.kubernetes.io/instance: kubernetes
              name: argocd-manager
              namespace: kube-system
        providerConfigRef:
          name: '{{ include "common-gitops.names.release" . }}'

      # Note: amazon vpc cni is managed from the eks addon.
      #       However, to enable windows support, we need to redeploy this configmap with custom changes
      amazon-vpc-cni:
        forProvider:
          manifest:
            apiVersion: v1
            kind: ConfigMap
            metadata:
              labels:
                app.kubernetes.io/name: '{{ include "common-gitops.names.release" . }}'
                app.kubernetes.io/instance: kubernetes
              name: amazon-vpc-cni
              namespace: kube-system
              # Windows support requires enable-windows-ipam set to true
            data:
              branch-eni-cooldown: "60"
              enable-network-policy-controller: "false"
              enable-windows-ipam: "true"
              enable-windows-prefix-delegation: "false"
              minimum-ip-target: "3"
              warm-ip-target: "1"
              warm-prefix-target: "0"
        providerConfigRef:
          name: '{{ include "common-gitops.names.release" . }}'

      clusterrole:
        forProvider:
          manifest:
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              labels:
                app.kubernetes.io/name: '{{ include "common-gitops.names.release" . }}'
                app.kubernetes.io/instance: kubernetes
              name: argocd-manager-role
            rules:
              - apiGroups:
                  - '*'
                resources:
                  - '*'
                verbs:
                  - '*'
              - nonResourceURLs:
                  - '*'
                verbs:
                  - '*'
        providerConfigRef:
          name: '{{ include "common-gitops.names.release" . }}'

      clusterrolebinding:
        forProvider:
          manifest:
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              labels:
                app.kubernetes.io/name: '{{ include "common-gitops.names.release" . }}'
                app.kubernetes.io/instance: kubernetes
              name: argocd-manager-role-binding
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: argocd-manager-role
            subjects:
              - kind: ServiceAccount
                name: argocd-manager
                namespace: kube-system
        providerConfigRef:
          name: '{{ include "common-gitops.names.release" . }}'
