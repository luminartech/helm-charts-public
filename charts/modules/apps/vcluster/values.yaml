---
## @section Global parameters
## Global parameters
## These variables are accessible to all dependency helm charts.
##

global:
  ## @param global.chartNameOverride Overrides the chart name.
  ##
  chartNameOverride: ""
  ## @param global.releaseNameOverride Overrides the release name.
  ##
  releaseNameOverride: ""
  ## @param global.tags Define common tags for all IAC and app resources generated by this chart.
  ##
  tags: {}
  ## @param global.labels Define common labels for all IAC and app resources generated by this chart.
  ##
  labels: {}
  ## @param global.annotations Define common annotations for all IAC and app resources generated by this chart.
  ##
  annotations: {}
  ## @param global.providerConfigRef.name Default crossplane provider all resources generated for crossplane.
  ##
  providerConfigRef:
    name: crossplane-provider-config-aws
  ## @param global.awsAccountId Default aws account id for crossplane aws provider resources. Quotes are important, value must be a string.
  ##
  awsAccountId: "0123456789"
  ## @param global.awsRegion Default aws region for crossplane aws provider resources.
  ##
  awsRegion: us-east-2
  ## @param global.eksHash Default EKS cluster hash for relevant crossplane resources such as IAM Role.
  ##
  eksHash: "XXXXX"
  ## @param global.eksClusterName Host EKS Cluster namee
  ##
  eksClusterName: infra-aws-eks
  ## @param global.githubRepoName Github repo name
  ##
  githubRepoName: gitops-infra-demo
  ## @param global.githubOrg Github Org name
  ##
  githubOrg: satish-labs
  ## @param global.githubPrNumber Github PR number
  ##
  githubPrNumber: "1"
  ## @param global.clusterOwner Vcluster owner
  ##
  clusterOwner: "engineer.name"
  ## @param global.argocdNamespace ArgoCD namespace
  ##
  argocdNamespace: infra-argo-cd
  ## @param global.clusterType K8s cluster type
  ##
  clusterType: vcluster
  ## @param global.clusterExternalDomain cluster external base domain
  ##
  clusterExternalDomain: infra-aws-eks
  ## @skip global.imagePullSecrets Image pull secrets
  ## @skip global.imagePullSecrets[0].name
  ##
  imagePullSecrets: [{name: "infra-dockerhub-creds"}]
  ## @param global.team Team name
  ##
  team: infra
  ## @param global.environment VCluster environment
  ##
  environment: dev
  ## @param global.ingressClassName Ingress class name for the vcluster ingresses
  ##
  ingressClassName: nginx-ingress-internal
  ## @param global.vclusterVersion VCluster version
  ##
  vclusterVersion: "v0.13.0"

## @skip vcluster
vcluster:
  enabled: false
  plugin:
    cert-manager-plugin:
      image: ghcr.io/loft-sh/vcluster-plugins/cert-manager-plugin:0.3.0@sha256:090dca62a52db3fa9bbab005c72d233b6b93cfc6a25e021c9e6415a424cd500d
      imagePullPolicy: IfNotPresent
      rbac:
        role:
          extraRules:
            - apiGroups: ["cert-manager.io"]
              resources: ["clusterissuers", "issuers", "certificates"]
              verbs: ["create", "delete", "patch", "update", "get", "list", "watch"]
        clusterRole:
          extraRules:
            - apiGroups: ["apiextensions.k8s.io"]
              resources: ["customresourcedefinitions"]
              verbs: ["get", "list", "watch"]
  # vcluster:
  #   extraArgs:
  #     - --tls-san=gitops-infra-core-pr-1.dev.domain.com

  init:
    manifestsTemplate: |
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: argocd-manager
        namespace: kube-system
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: argocd-manager-role
      rules:
        - apiGroups:
            - '*'
          resources:
            - '*'
          verbs:
            - '*'
        - nonResourceURLs:
            - '*'
          verbs:
            - '*'
      ---
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: argocd-manager-role-binding
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: argocd-manager-role
      subjects:
        - kind: ServiceAccount
          name: argocd-manager
          namespace: kube-system
      ---
      # This is required only for kubernetes 1.24+
      # https://github.com/argoproj/argo-cd/issues/9610
      # https://github.com/argoproj/argo-cd/issues/4651
      apiVersion: v1
      kind: Secret
      metadata:
        name: argocd-manager-token
        namespace: kube-system
        annotations:
          kubernetes.io/service-account.name: argocd-manager
      type: kubernetes.io/service-account-token

  sync:
    ingresses:
      enabled: true
    hoststorageclasses:
      enabled: true
  storage:
    persistence: false

  # syncer:
    # kubeConfigContextName: gitops-infra-core-pr-1
    # extraArgs:
    #   - --tls-san=gitops-infra-core-pr-1.dev.domain.com
    #   - --out-kube-config-server=https://gitops-infra-core-pr-1.dev.domain.com

  replicas: 1

  # isolation:
  #   networkPolicy:
  #     enabled: "false"

  multiNamespaceMode:
    enabled: false

  ingress:
    enabled: false
    ingressClassName: nginx-ingress-internal
    host: "ingress.local"
    annotations:
      nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/ssl-passthrough: "true"
      kubernetes.io/ingress.allow-http: "false"

## @skip external-secrets
external-secrets:
  enabled: false
  external-secrets:
    enabled: false

  VclusterExternalSecret:
    enabled: false
    items:
      ss:
        namespace: '{{ .Release.Namespace }}'
        # annotations:
        #   "helm.sh/hook": post-install,post-upgrade
        #   "helm.sh/hook-weight": "100"
        #   "helm.sh/hook-delete-policy": before-hook-creation
        refreshInterval: 2m
        deletionPolicy: Delete
        creationPolicy: Owner
        targetSecretName: 'vc-{{ .Release.Name }}'
        k8sClusterSecretName: 'vc-{{ .Release.Name }}'
        argoCdSaTokenSecretName: 'vc-{{ .Release.Name }}-argo-cd-sa-token'
        k8sClusterEndpoint: 'https://{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{.Values.global.environment}}.{{ .Values.global.clusterExternalDomain }}'
        # https://github.com/loft-sh/vcluster/issues/595#issuecomment-1367908077
        # Vcluster is currently having issues with additional san option
        # For now, we need to enable insecure option and remove caData from the config
        insecureEnabled: true
        # keep this false when insecure is enabled
        caDataEnabled: false
        targetAnnotations:
          kubed.appscode.com/sync: "kubernetes.io/metadata.name={{ .Values.global.argocdNamespace }}"
          providerConfigRefName:  "{{ .Values.global.providerConfigRef.name }}"
          eksClusterName: '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}'
          clusterType: '{{ .Values.global.clusterType }}'
          team: '{{ .Values.global.team }}'
          environment: 'test'
          awsAccountId: "{{ .Values.global.awsAccountId }}"
          awsRegion: "{{ .Values.global.awsRegion }}"
          githubRepoName: '{{ .Values.global.githubRepoName }}'
          githubOrg: '{{ .Values.global.githubOrg }}'
          githubPrNumber: '{{ .Values.global.githubPrNumber }}'
          clusterExternalDomain: '{{ .Values.global.clusterExternalDomain }}'
          clusterOwner: '{{ .Values.global.clusterOwner }}'
          serviceMonitor: "false"
          podMonitor: "false"
          metrics: "false"
          ingressClassNameInternal: "{{ .Values.global.ingressClassName }}"
        targetLabels:
          argocd.argoproj.io/secret-type: cluster
          vcluster: "true"

  ExternalSecretRole:
    enabled: true
    items:
      ss:
        namespace: '{{ .Release.Namespace }}'

  ExternalSecretRoleBinding:
    enabled: true
    items:
      ss:
        namespace: '{{ .Release.Namespace }}'

  SecretStore:
    enabled: true
    items:
      ss:
        namespace: '{{ .Release.Namespace }}'
        provider:
          kubernetes:
            remoteNamespace: '{{ .Release.Namespace }}'
            server:
              url: "https://kubernetes.default.svc"
              caProvider:
                type: ConfigMap
                name: kube-root-ca.crt
                key: ca.crt

  ExternalSecretsServiceAccount:
    enabled: true
    items:
      ss:
        namespace: '{{ .Release.Namespace }}'

## @skip common-res
common-res:
  enabled: false

  Ingress:
    enabled: false
    items:
      _:
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
          nginx.ingress.kubernetes.io/ssl-passthrough: "true"
          # nginx.ingress.kubernetes.io/server-snippet: |
          #   proxy_ssl_verify off;
          #   proxy_set_header X-Forwarded-Proto https;
          kubernetes.io/ingress.allow-http: "false"
          # kubernetes.io/tls-acme: "true"
          # cert-manager.io/acme-challenge-type: dns01
          # cert-manager.io/acme-dns01-provider: route53
          # cert-manager.io/cluster-issuer: '{{ .Values.global.team }}-{{ .Values.global.clusterExternalDomain | replace "." "-" }}'
        spec:
          ingressClassName: '{{ .Values.global.ingressClassName }}'
          rules:
            - host: '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{.Values.global.environment}}.{{ .Values.global.clusterExternalDomain }}'
              http:
                paths:
                  - path: /
                    pathType: ImplementationSpecific
                    backend:
                      service:
                        name: '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}'
                        port:
                          name: https
          # tls:
          #   - secretName: 'tls-{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{.Values.global.environment}}.{{ .Values.global.clusterExternalDomain }}'
          #     hosts:
          #       - '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{.Values.global.environment}}.{{ .Values.global.clusterExternalDomain }}'

  Job:
    enabled: true
    items:
      # This job exists because there's no elegant solution known as of now to run CronJob (below) upon helm chart install
      get-argocd-token:
        # annotations:
        #   "helm.sh/hook": post-install,post-upgrade
        #   "helm.sh/hook-weight": "-5"
        #   "helm.sh/hook-delete-policy": before-hook-creation
        podSpec:
          spec:
            serviceAccountName: vc-{{ .Release.Name }}
            containers:
              - name: get-argocd-token
                image: "efrecon/vcluster:{{ .Values.global.vclusterVersion }}"
                env:
                  - name: RELEASE_NAME
                    value: '{{ .Release.Name }}'
                  - name: VCLUSTER_SERVER
                    value: '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{ .Values.global.environment }}.{{ .Values.global.clusterExternalDomain }}'
                volumeMounts:
                  - name: get-token-script
                    mountPath: /scripts
                    readOnly: true
                command: ['sh', '/scripts/get-token.sh']
                # args:
                #   - sleep 604800
            volumes:
              - name: get-token-script
                configMap:
                  name: '{{ .Release.Name }}-get-token-script'
  CronJob:
    # Presumably k3s token expires in 24 hours. Enable this CronJob if you would like to keep token fresh
    enabled: false
    items:
      refresh-argocd-token:
        schedule: "0 */22 * * *"
        jobTemplate:
          spec:
            template:
              spec:
                serviceAccountName: vc-{{ .Release.Name }}
                containers:
                  - name: get-argocd-token
                    image: "efrecon/vcluster:{{ .Values.global.vclusterVersion }}"
                    env:
                      - name: RELEASE_NAME
                        value: '{{ .Release.Name }}'
                      - name: VCLUSTER_SERVER
                        value: '{{ .Values.global.githubRepoName }}-pr-{{ .Values.global.githubPrNumber }}.{{ .Values.global.environment }}.{{ .Values.global.clusterExternalDomain }}'
                    volumeMounts:
                      - name: get-token-script
                        mountPath: /scripts
                        readOnly: true
                    command: ['sh', '/scripts/get-token.sh']
                volumes:
                  - name: get-token-script
                    configMap:
                      name: '{{ .Release.Name }}-get-token-script'

  ServiceAccount:
    enabled: true

  Role:
    enabled: true

  RoleBinding:
    enabled: true
    items:
      github-events-access:
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: "github-events-{{ .Values.global.githubRepoName }}"
        subjects:
          # grant github-event sensors permission to manage workflows in vcluster namespace
          - kind: ServiceAccount
            name: github-events-{{ .Values.global.githubRepoName }}
            namespace: github-events-{{ .Values.global.githubRepoName }}
      argo-access:
        # grant argo-workflows permission to manage workflows in vcluster namespace
        # TODO: check if this rb is needed after making argo-workflows cluster scoped deployment
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: "{{ .Values.global.environment }}-argo-workflows-workflow-controller"
        subjects:
          - kind: ServiceAccount
            name: "{{ .Values.global.environment }}-argo-workflows-workflow-controller"
            namespace: "{{ .Values.global.environment }}-argo-workflows"
